// Code generated by cue get go. DO NOT EDIT.

//cue:generate cue get go github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1

package v1alpha1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	prom_v1 "github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
	"k8s.io/api/core/v1"
)

// LogsSubsystemSpec defines global settings to apply across the logging
// subsystem.
#LogsSubsystemSpec: {
	// A global set of clients to use when a discovered LogsInstance does not
	// have any clients defined.
	clients?: [...#LogsClientSpec] @go(Clients,[]LogsClientSpec)

	// LogsExternalLabelName is the name of the external label used to
	// denote Grafana Agent cluster. Defaults to "cluster." External label will
	// _not_ be added when value is set to the empty string.
	logsExternalLabelName?: null | string @go(LogsExternalLabelName,*string)

	// InstanceSelector determines which LogInstances should be selected
	// for running. Each instance runs its own set of Prometheus components,
	// including service discovery, scraping, and remote_write.
	instanceSelector?: null | metav1.#LabelSelector @go(InstanceSelector,*metav1.LabelSelector)

	// InstanceNamespaceSelector are the set of labels to determine which
	// namespaces to watch for LogInstances. If not provided, only checks own
	// namespace.
	instanceNamespaceSelector?: null | metav1.#LabelSelector @go(InstanceNamespaceSelector,*metav1.LabelSelector)

	// IgnoreNamespaceSelectors, if true, will ignore NamespaceSelector settings
	// from the PodLogs configs, and they will only discover endpoints within
	// their current namespace.
	ignoreNamespaceSelectors?: bool @go(IgnoreNamespaceSelectors)

	// EnforcedNamespaceLabel enforces adding a namespace label of origin for
	// each metric that is user-created. The label value will always be the
	// namespace of the object that is being created.
	enforcedNamespaceLabel?: string @go(EnforcedNamespaceLabel)
}

// LogsClientSpec defines the client integration for logs, indicating which
// Loki server to send logs to.
#LogsClientSpec: {
	// URL is the URL where Loki is listening. Must be a full HTTP URL, including
	// protocol. Required.
	// Example: https://logs-prod-us-central1.grafana.net/loki/api/v1/push.
	url: string @go(URL)

	// Tenant ID used by default to push logs to Loki. If omitted assumes remote
	// Loki is running in single-tenant mode or an authentication layer is used
	// to inject an X-Scope-OrgID header.
	tenantId?: string @go(TenantID)

	// Maximum amount of time to wait before sending a batch, even if that batch
	// isn't full.
	batchWait?: string @go(BatchWait)

	// Maximum batch size (in bytes) of logs to accumulate before sending the
	// batch to Loki.
	batchSize?: int @go(BatchSize)

	// BasicAuth for the Loki server.
	basicAuth?: null | prom_v1.#BasicAuth @go(BasicAuth,*prom_v1.BasicAuth)

	// BearerToken used for remote_write.
	bearerToken?: string @go(BearerToken)

	// BearerTokenFile used to read bearer token.
	bearerTokenFile?: string @go(BearerTokenFile)

	// ProxyURL to proxy requests through. Optional.
	proxyUrl?: string @go(ProxyURL)

	// TLSConfig to use for the client. Only used when the protocol of the URL
	// is https.
	tlsConfig?: null | prom_v1.#TLSConfig @go(TLSConfig,*prom_v1.TLSConfig)

	// Configures how to retry requests to Loki when a request fails.
	// Defaults to a minPeriod of 500ms, maxPeriod of 5m, and maxRetries of 10.
	backoffConfig?: null | #LogsBackoffConfigSpec @go(BackoffConfig,*LogsBackoffConfigSpec)

	// ExternalLabels are labels to add to any time series when sending data to
	// Loki.
	externalLabels?: {[string]: string} @go(ExternalLabels,map[string]string)

	// Maximum time to wait for a server to respond to a request.
	timeout?: string @go(Timeout)
}

// LogsBackoffConfigSpec configures timing for retrying failed requests.
#LogsBackoffConfigSpec: {
	// Initial backoff time between retries. Time between retries is
	// increased exponentially.
	minPeriod?: string @go(MinPeriod)

	// Maximum backoff time between retries.
	maxPeriod?: string @go(MaxPeriod)

	// Maximum number of retries to perform before giving up a request.
	maxRetries?: int @go(MaxRetries)
}

// LogsInstance controls an individual logs instance within a Grafana Agent
// deployment.
#LogsInstance: {
	metav1.#TypeMeta
	metadata?: metav1.#ObjectMeta @go(ObjectMeta)

	// Spec holds the specification of the desired behavior for the logs
	// instance.
	spec?: #LogsInstanceSpec @go(Spec)
}

// LogsInstanceSpec controls how an individual instance will be used to
// discover LogMonitors.
#LogsInstanceSpec: {
	// Clients controls where logs are written to for this instance.
	clients?: [...#LogsClientSpec] @go(Clients,[]LogsClientSpec)

	// Determines which PodLogs should be selected for including in this
	// instance.
	podLogsSelector?: null | metav1.#LabelSelector @go(PodLogsSelector,*metav1.LabelSelector)

	// Set of labels to determine which namespaces should be watched
	// for PodLogs. If not provided, checks only namespace of the
	// instance.
	podLogsNamespaceSelector?: null | metav1.#LabelSelector @go(PodLogsNamespaceSelector,*metav1.LabelSelector)

	// AdditionalScrapeConfigs allows specifying a key of a Secret containing
	// additional Grafana Agent logging scrape configurations. Scrape
	// configurations specified are appended to the configurations generated by
	// the Grafana Agent Operator.
	//
	// Job configurations specified must have the form as specified in the
	// official Promtail documentation:
	//
	// https://grafana.com/docs/loki/latest/clients/promtail/configuration/#scrape_configs
	//
	// As scrape configs are appended, the user is responsible to make sure it is
	// valid. Note that using this feature may expose the possibility to break
	// upgrades of Grafana Agent. It is advised to review both Grafana Agent and
	// Promtail release notes to ensure that no incompatible scrape configs are
	// going to break Grafana Agent after the upgrade.
	additionalScrapeConfigs?: null | v1.#SecretKeySelector @go(AdditionalScrapeConfigs,*v1.SecretKeySelector)

	// Configures how tailed targets are watched.
	targetConfig?: null | #LogsTargetConfigSpec @go(TargetConfig,*LogsTargetConfigSpec)
}

// LogsTargetConfigSpec configures how tailed targets are watched.
#LogsTargetConfigSpec: {
	// Period to resync directories being watched and files being tailed to discover
	// new ones or stop watching removed ones.
	syncPeriod?: string @go(SyncPeriod)
}

// LogsInstanceList is a list of LogsInstance.
#LogsInstanceList: {
	metav1.#TypeMeta
	metadata?: metav1.#ListMeta @go(ListMeta)

	// Items is the list of LogsInstance.
	items: [...null | #LogsInstance] @go(Items,[]*LogsInstance)
}

// PodLogs defines how to collect logs for a pod.
#PodLogs: {
	metav1.#TypeMeta
	metadata?: metav1.#ObjectMeta @go(ObjectMeta)

	// Spec holds the specification of the desired behavior for the PodLogs.
	spec?: #PodLogsSpec @go(Spec)
}

// PodLogsSpec defines how to collect logs for a pod.
#PodLogsSpec: {
	// The label to use to retrieve the job name from.
	jobLabel?: string @go(JobLabel)

	// PodTargetLabels transfers labels on the Kubernetes Pod onto the target.
	podTargetLabels?: [...string] @go(PodTargetLabels,[]string)

	// Selector to select Pod objects. Required.
	selector: metav1.#LabelSelector @go(Selector)

	// Selector to select which namespaces the Pod objects are discovered from.
	namespaceSelector?: prom_v1.#NamespaceSelector @go(NamespaceSelector)

	// Pipeline stages for this pod. Pipeline stages support transforming and
	// filtering log lines.
	pipelineStages?: [...null | #PipelineStageSpec] @go(PipelineStages,[]*PipelineStageSpec)

	// RelabelConfigs to apply to logs before delivering.
	// Grafana Agent Operator automatically adds relabelings for a few standard
	// Kubernetes fields and replaces original scrape job name with
	// __tmp_logs_job_name.
	//
	// More info: https://grafana.com/docs/loki/latest/clients/promtail/configuration/#relabel_configs
	relabelings?: [...null | prom_v1.#RelabelConfig] @go(RelabelConfigs,[]*prom_v1.RelabelConfig)
}

// PodLogsList is a list of PodLogs.
#PodLogsList: {
	metav1.#TypeMeta
	metadata?: metav1.#ListMeta @go(ListMeta)

	// Items is the list of PodLogs.
	items: [...null | #PodLogs] @go(Items,[]*PodLogs)
}

// PipelineStageSpec defines an individual pipeline stage. Each stage type is
// mutually exclusive and no more than one may be set per stage.
//
// More information on pipelines can be found in the Promtail documentation:
// https://grafana.com/docs/loki/latest/clients/promtail/pipelines/
#PipelineStageSpec: {
	// CRI is a parsing stage that reads log lines using the standard
	// CRI logging format. Supply cri: {} to enable.
	cri?: null | #CRIStageSpec @go(CRI,*CRIStageSpec)

	// Docker is a parsing stage that reads log lines using the standard
	// Docker logging format. Supply docker: {} to enable.
	docker?: null | #DockerStageSpec @go(Docker,*DockerStageSpec)

	// Drop is a filtering stage that lets you drop certain logs.
	drop?: null | #DropStageSpec @go(Drop,*DropStageSpec)

	// JSON is a parsing stage that reads the log line as JSON and accepts
	// JMESPath expressions to extract data.
	//
	// Information on JMESPath: http://jmespath.org/
	json?: null | #JSONStageSpec @go(JSON,*JSONStageSpec)

	// LabelAllow is an action stage that only allows the provided labels to be
	// included in the label set that is sent to Loki with the log entry.
	labelAllow?: [...string] @go(LabelAllow,[]string)

	// LabelDrop is an action stage that drops labels from the label set that
	// is sent to Loki with the log entry.
	labelDrop?: [...string] @go(LabelDrop,[]string)

	// Labels is an action stage that takes data from the extracted map and
	// modifies the label set that is sent to Loki with the log entry.
	//
	// The key is REQUIRED and represents the name for the label that will
	// be created. Value is optional and will be the name from extracted data
	// to use for the value of the label. If the value is not provided, it
	// defaults to match the key.
	labels?: {[string]: string} @go(Labels,map[string]string)

	// Limit is a rate-limiting stage that throttles logs based on
	// several options.
	limit?: null | #LimitStageSpec @go(Limit,*LimitStageSpec)

	// Match is a filtering stage that conditionally applies a set of stages
	// or drop entries when a log entry matches a configurable LogQL stream
	// selector and filter expressions.
	match?: null | #MatchStageSpec @go(Match,*MatchStageSpec)

	// Metrics is an action stage that supports defining and updating metrics
	// based on data from the extracted map. Created metrics are not pushed to
	// Loki or Prometheus and are instead exposed via the /metrics endpoint of
	// the Grafana Agent pod. The Grafana Agent Operator should be configured
	// with a MetricsInstance that discovers the logging DaemonSet to collect
	// metrics created by this stage.
	metrics?: {[string]: #MetricsStageSpec} @go(Metrics,map[string]MetricsStageSpec)

	// Multiline stage merges multiple lines into a multiline block before
	// passing it on to the next stage in the pipeline.
	multiline?: null | #MultilineStageSpec @go(Multiline,*MultilineStageSpec)

	// Output stage is an action stage that takes data from the extracted map and
	// changes the log line that will be sent to Loki.
	output?: null | #OutputStageSpec @go(Output,*OutputStageSpec)

	// Pack is a transform stage that lets you embed extracted values and labels
	// into the log line by packing the log line and labels inside of a JSON
	// object.
	pack?: null | #PackStageSpec @go(Pack,*PackStageSpec)

	// Regex is a parsing stage that parses a log line using a regular
	// expression.  Named capture groups in the regex allows for adding data into
	// the extracted map.
	regex?: null | #RegexStageSpec @go(Regex,*RegexStageSpec)

	// Replace is a parsing stage that parses a log line using a regular
	// expression and replaces the log line. Named capture groups in the regex
	// allows for adding data into the extracted map.
	replace?: null | #ReplaceStageSpec @go(Replace,*ReplaceStageSpec)

	// Template is a transform stage that manipulates the values in the extracted
	// map using Go's template syntax.
	template?: null | #TemplateStageSpec @go(Template,*TemplateStageSpec)

	// Tenant is an action stage that sets the tenant ID for the log entry picking it from a
	// field in the extracted data map. If the field is missing, the default
	// LogsClientSpec.tenantId will be used.
	tenant?: null | #TenantStageSpec @go(Tenant,*TenantStageSpec)

	// Timestamp is an action stage that can change the timestamp of a log line
	// before it is sent to Loki. If not present, the timestamp of a log line
	// defaults to the time when the log line was read.
	timestamp?: null | #TimestampStageSpec @go(Timestamp,*TimestampStageSpec)
}

// CRIStageSpec is a parsing stage that reads log lines using the standard CRI
// logging format. It needs no defined fields.
#CRIStageSpec: {
}

// DockerStageSpec is a parsing stage that reads log lines using the standard
// Docker logging format. It needs no defined fields.
#DockerStageSpec: {
}

// DropStageSpec is a filtering stage that lets you drop certain logs.
#DropStageSpec: {
	// Name from the extract data to parse. If empty, uses the log message.
	source?: string @go(Source)

	// RE2 regular expression.
	//
	// If source is provided, the regex attempts
	// to match the source.
	//
	// If no source is provided, then the regex attempts
	// to attach the log line.
	//
	// If the provided regex matches the log line or a provided source, the
	// line is dropped.
	expression?: string @go(Expression)

	// Value can only be specified when source is specified. If the value
	// provided is an exact match for the given source then the line will be
	// dropped.
	//
	// Mutually exclusive with expression.
	value?: string @go(Value)

	// OlderThan will be parsed as a Go duration. If the log line's timestamp
	// is older than the current time minus the provided duration, it will be
	// dropped.
	olderThan?: string @go(OlderThan)

	// LongerThan will drop a log line if it its content is longer than this
	// value (in bytes). Can be expressed as an integer (8192) or a number with a
	// suffix (8kb).
	longerThan?: string @go(LongerThan)

	// Every time a log line is dropped, the metric logentry_dropped_lines_total
	// is incremented. A "reason" label is added, and can be customized by
	// providing a custom value here. Defaults to "drop_stage".
	dropCounterReason?: string @go(DropCounterReason)
}

// JSONStageSpec is a parsing stage that reads the log line as JSON and accepts
// JMESPath expressions to extract data.
#JSONStageSpec: {
	// Name from the extracted data to parse as JSON. If empty, uses entire log
	// message.
	source?: string @go(Source)

	// Set of the key/value pairs of JMESPath expressions. The key will be the
	// key in the extracted data while the expression will be the value,
	// evaluated as a JMESPath from the source data.
	//
	// Literal JMESPath expressions can be used by wrapping a key in double
	// quotes, which then must be wrapped again in single quotes in YAML
	// so they get passed to the JMESPath parser.
	expressions?: {[string]: string} @go(Expressions,map[string]string)
}

// The limit stage is a rate-limiting stage that throttles logs based on
// several options.
#LimitStageSpec: {
	// The rate limit in lines per second that Promtail will push to Loki.
	rate?: int @go(Rate)

	// The cap in the quantity of burst lines that Promtail will push to Loki.
	burst?: int @go(Burst)

	// When drop is true, log lines that exceed the current rate limit are discarded.
	// When drop is false, log lines that exceed the current rate limit wait
	// to enter the back pressure mode.
	//
	// Defaults to false.
	drop?: bool @go(Drop)
}

// MatchStageSpec is a filtering stage that conditionally applies a set of
// stages or drop entries when a log entry matches a configurable LogQL stream
// selector and filter expressions.
#MatchStageSpec: {
	// LogQL stream selector and filter expressions. Required.
	selector: string @go(Selector)

	// Names the pipeline. When defined, creates an additional label
	// in the pipeline_duration_seconds histogram, where the value is
	// concatenated with job_name using an underscore.
	pipelineName?: string @go(PipelineName)

	// Determines what action is taken when the selector matches the log line.
	// Can be keep or drop. Defaults to keep. When set to drop, entries are
	// dropped and no later metrics are recorded.
	// Stages must be empty when dropping metrics.
	action?: string @go(Action)

	// Every time a log line is dropped, the metric logentry_dropped_lines_total
	// is incremented. A "reason" label is added, and can be customized by
	// providing a custom value here. Defaults to "match_stage."
	dropCounterReason?: string @go(DropCounterReason)

	// Nested set of pipeline stages to execute when action is keep and the log
	// line matches selector.
	//
	// An example value for stages may be:
	//
	//   stages: |
	//     - json: {}
	//     - labelAllow: [foo, bar]
	//
	// Note that stages is a string because SIG API Machinery does not
	// support recursive types, and so it cannot be validated for correctness. Be
	// careful not to mistype anything.
	stages?: string @go(Stages)
}

// MetricsStageSpec is an action stage that allows for defining and updating
// metrics based on data from the extracted map. Created metrics are not pushed
// to Loki or Prometheus and are instead exposed via the /metrics endpoint of
// the Grafana Agent pod. The Grafana Agent Operator should be configured with
// a MetricsInstance that discovers the logging DaemonSet to collect metrics
// created by this stage.
#MetricsStageSpec: {
	// The metric type to create. Must be one of counter, gauge, histogram.
	// Required.
	type: string @go(Type)

	// Sets the description for the created metric.
	description?: string @go(Description)

	// Sets the custom prefix name for the metric. Defaults to "promtail_custom_".
	prefix?: string @go(Prefix)

	// Key from the extracted data map to use for the metric. Defaults to the
	// metrics name if not present.
	source?: string @go(Source)

	// Label values on metrics are dynamic which can cause exported metrics
	// to go stale. To prevent unbounded cardinality, any metrics not updated
	// within MaxIdleDuration are removed.
	//
	// Must be greater or equal to 1s. Defaults to 5m.
	maxIdleDuration?: string @go(MaxIdleDuration)

	// If true, all log lines are counted without attempting to match the
	// source to the extracted map. Mutually exclusive with value.
	//
	// Only valid for type: counter.
	matchAll?: null | bool @go(MatchAll,*bool)

	// If true all log line bytes are counted. Can only be set with
	// matchAll: true and action: add.
	//
	// Only valid for type: counter.
	countEntryBytes?: null | bool @go(CountEntryBytes,*bool)

	// Filters down source data and only changes the metric if the targeted
	// value matches the provided string exactly. If not present, all
	// data matches.
	value?: string @go(Value)

	// The action to take against the metric. Required.
	//
	// Must be either "inc" or "add" for type: counter or type: histogram.
	// When type: gauge, must be one of "set", "inc", "dec", "add", or "sub".
	//
	// "add", "set", or "sub" requires the extracted value to be convertible
	// to a positive float.
	action: string @go(Action)

	// Buckets to create. Bucket values must be convertible to float64s. Extremely
	// large or small numbers are subject to some loss of precision.
	// Only valid for type: histogram.
	buckets?: [...string] @go(Buckets,[]string)
}

// MultilineStageSpec merges multiple lines into a multiline block before
// passing it on to the next stage in the pipeline.
#MultilineStageSpec: {
	// RE2 regular expression. Creates a new multiline block when matched.
	// Required.
	firstLine: string @go(FirstLine)

	// Maximum time to wait before passing on the multiline block to the next
	// stage if no new lines are received. Defaults to 3s.
	maxWaitTime?: string @go(MaxWaitTime)

	// Maximum number of lines a block can have. A new block is started if
	// the number of lines surpasses this value. Defaults to 128.
	maxLines?: int @go(MaxLines)
}

// OutputStageSpec is an action stage that takes data from the extracted map
// and changes the log line that will be sent to Loki.
#OutputStageSpec: {
	// Name from extract data to use for the log entry. Required.
	source: string @go(Source)
}

// PackStageSpec is a transform stage that lets you embed extracted values and
// labels into the log line by packing the log line and labels inside of a JSON
// object.
#PackStageSpec: {
	// Name from extracted data or line labels. Required.
	// Labels provided here are automatically removed from output labels.
	labels: [...string] @go(Labels,[]string)

	// If the resulting log line should use any existing timestamp or use time.Now()
	// when the line was created. Set to true when combining several log streams from
	// different containers to avoid out of order errors.
	ingestTimestamp?: bool @go(IngestTimestamp)
}

// RegexStageSpec is a parsing stage that parses a log line using a regular
// expression. Named capture groups in the regex allows for adding data into
// the extracted map.
#RegexStageSpec: {
	// Name from extracted data to parse. If empty, defaults to using the log
	// message.
	source?: string @go(Source)

	// RE2 regular expression. Each capture group MUST be named. Required.
	expression: string @go(Expression)
}

// ReplaceStageSpec is a parsing stage that parses a log line using a regular
// expression and replaces the log line. Named capture groups in the regex
// allows for adding data into the extracted map.
#ReplaceStageSpec: {
	// Name from extracted data to parse. If empty, defaults to using the log
	// message.
	source?: string @go(Source)

	// RE2 regular expression. Each capture group MUST be named. Required.
	expression: string @go(Expression)

	// Value to replace the captured group with.
	replace?: string @go(Replace)
}

// TemplateStageSpec is a transform stage that manipulates the values in the
// extracted map using Go's template syntax.
#TemplateStageSpec: {
	// Name from extracted data to parse. Required. If empty, defaults to using
	// the log message.
	source: string @go(Source)

	// Go template string to use. Required. In addition to normal template
	// functions, ToLower, ToUpper, Replace, Trim, TrimLeft, TrimRight,
	// TrimPrefix, and TrimSpace are also available.
	template: string @go(Template)
}

// TenantStageSpec is an action stage that sets the tenant ID for the log entry
// picking it from a field in the extracted data map.
#TenantStageSpec: {
	// Name from labels whose value should be set as tenant ID. Mutually exclusive with
	// source and value.
	label?: string @go(Label)

	// Name from extracted data to use as the tenant ID. Mutually exclusive with
	// label and value.
	source?: string @go(Source)

	// Value to use for the template ID. Useful when this stage is used within a
	// conditional pipeline such as match. Mutually exclusive with label and source.
	value?: string @go(Value)
}

// TimestampStageSpec is an action stage that can change the timestamp of a log
// line before it is sent to Loki.
#TimestampStageSpec: {
	// Name from extracted data to use as the timestamp. Required.
	source: string @go(Source)

	// Determines format of the time string. Required. Can be one of:
	// ANSIC, UnixDate, RubyDate, RFC822, RFC822Z, RFC850, RFC1123, RFC1123Z,
	// RFC3339, RFC3339Nano, Unix, UnixMs, UnixUs, UnixNs.
	format: string @go(Format)

	// Fallback formats to try if format fails.
	fallbackFormats?: [...string] @go(FallbackFormats,[]string)

	// IANA Timezone Database string.
	location?: string @go(Location)

	// Action to take when the timestamp can't be extracted or parsed.
	// Can be skip or fudge. Defaults to fudge.
	actionOnFailure?: string @go(ActionOnFailure)
}
